\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Artificial Neural Networks (ANNs)}{10}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neuron}{10}{section.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Simplified Biological Neuron}}{10}{figure.2.1}\protected@file@percent }
\newlabel{fig:enter-label}{{2.1}{10}{Simplified Biological Neuron}{figure.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Mathematical Representation of Artificial Neuron}}{11}{figure.2.2}\protected@file@percent }
\newlabel{fig:enter-label}{{2.2}{11}{Mathematical Representation of Artificial Neuron}{figure.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Vector Representation of Artificial Neuron}}{11}{figure.2.3}\protected@file@percent }
\newlabel{fig:enter-label}{{2.3}{11}{Vector Representation of Artificial Neuron}{figure.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Activation Function}{11}{section.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Linear Activation Function}}{12}{figure.2.4}\protected@file@percent }
\newlabel{fig:enter-label}{{2.4}{12}{Linear Activation Function}{figure.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Most datasets are not linearly separable like A}}{12}{figure.2.5}\protected@file@percent }
\newlabel{fig:enter-label}{{2.5}{12}{Most datasets are not linearly separable like A}{figure.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Perceptrons}}{13}{figure.2.6}\protected@file@percent }
\newlabel{fig:enter-label}{{2.6}{13}{Perceptrons}{figure.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Sigmoid Function}}{14}{figure.2.7}\protected@file@percent }
\newlabel{fig:enter-label}{{2.7}{14}{Sigmoid Function}{figure.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Vanishing Gradient Problem}}{14}{figure.2.8}\protected@file@percent }
\newlabel{fig:enter-label}{{2.8}{14}{Vanishing Gradient Problem}{figure.2.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces ReLU Activation Function}}{15}{figure.2.9}\protected@file@percent }
\newlabel{fig:enter-label}{{2.9}{15}{ReLU Activation Function}{figure.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Training Neural Networks}{16}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Loss Function}{16}{section.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Learning Curves}}{17}{figure.2.10}\protected@file@percent }
\newlabel{fig:enter-label}{{2.10}{17}{Learning Curves}{figure.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Why we need Softmax}}{17}{figure.2.11}\protected@file@percent }
\newlabel{fig:enter-label}{{2.11}{17}{Why we need Softmax}{figure.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Softmax Function}}{17}{figure.2.12}\protected@file@percent }
\newlabel{fig:enter-label}{{2.12}{17}{Softmax Function}{figure.2.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces One-hot encoding}}{18}{figure.2.13}\protected@file@percent }
\newlabel{fig:enter-label}{{2.13}{18}{One-hot encoding}{figure.2.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Mean Squared Error}}{18}{figure.2.14}\protected@file@percent }
\newlabel{fig:enter-label}{{2.14}{18}{Mean Squared Error}{figure.2.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Cross Entropy Error}}{19}{figure.2.15}\protected@file@percent }
\newlabel{fig:enter-label}{{2.15}{19}{Cross Entropy Error}{figure.2.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Gradient Descent}{19}{section.2.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.16}{\ignorespaces NN layer represented by vectors}}{19}{figure.2.16}\protected@file@percent }
\newlabel{fig:enter-label}{{2.16}{19}{NN layer represented by vectors}{figure.2.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.17}{\ignorespaces Gradient Descent. The graph represents the Error (loss) function and the red tangent line is gradient of loss.}}{20}{figure.2.17}\protected@file@percent }
\newlabel{fig:enter-label}{{2.17}{20}{Gradient Descent. The graph represents the Error (loss) function and the red tangent line is gradient of loss}{figure.2.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.18}{\ignorespaces Delta Rule Example}}{21}{figure.2.18}\protected@file@percent }
\newlabel{fig:enter-label}{{2.18}{21}{Delta Rule Example}{figure.2.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Neural Network Architectures}{22}{section.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.19}{\ignorespaces XOR Function}}{22}{figure.2.19}\protected@file@percent }
\newlabel{fig:enter-label}{{2.19}{22}{XOR Function}{figure.2.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.20}{\ignorespaces Backpropogation}}{23}{figure.2.20}\protected@file@percent }
\newlabel{fig:enter-label}{{2.20}{23}{Backpropogation}{figure.2.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.21}{\ignorespaces Multiple Layers with Non-Linearity}}{23}{figure.2.21}\protected@file@percent }
\newlabel{fig:enter-label}{{2.21}{23}{Multiple Layers with Non-Linearity}{figure.2.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.22}{\ignorespaces 2-Layer Neural Network}}{24}{figure.2.22}\protected@file@percent }
\newlabel{fig:enter-label}{{2.22}{24}{2-Layer Neural Network}{figure.2.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.23}{\ignorespaces 3-Layer Neural Network}}{24}{figure.2.23}\protected@file@percent }
\newlabel{fig:enter-label}{{2.23}{24}{3-Layer Neural Network}{figure.2.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Hyperparameters}{26}{section.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.24}{\ignorespaces How split data affects optimization}}{26}{figure.2.24}\protected@file@percent }
\newlabel{fig:enter-label}{{2.24}{26}{How split data affects optimization}{figure.2.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.25}{\ignorespaces Grid Search and Random Search}}{26}{figure.2.25}\protected@file@percent }
\newlabel{fig:enter-label}{{2.25}{26}{Grid Search and Random Search}{figure.2.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Optimizers}{27}{section.2.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.26}{\ignorespaces Stochastic Gradient Descent}}{27}{figure.2.26}\protected@file@percent }
\newlabel{fig:enter-label}{{2.26}{27}{Stochastic Gradient Descent}{figure.2.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.27}{\ignorespaces SGD with Momentum}}{28}{figure.2.27}\protected@file@percent }
\newlabel{fig:enter-label}{{2.27}{28}{SGD with Momentum}{figure.2.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.28}{\ignorespaces Optimizers relative to each other in terms of training cost over iterations}}{29}{figure.2.28}\protected@file@percent }
\newlabel{fig:enter-label}{{2.28}{29}{Optimizers relative to each other in terms of training cost over iterations}{figure.2.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.29}{\ignorespaces Adam Optimizer Equations}}{30}{figure.2.29}\protected@file@percent }
\newlabel{fig:enter-label}{{2.29}{30}{Adam Optimizer Equations}{figure.2.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Learning Rate}{30}{section.2.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.30}{\ignorespaces Learning Rate Size}}{31}{figure.2.30}\protected@file@percent }
\newlabel{fig:enter-label}{{2.30}{31}{Learning Rate Size}{figure.2.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.31}{\ignorespaces How learning rate changes over epochs}}{31}{figure.2.31}\protected@file@percent }
\newlabel{fig:enter-label}{{2.31}{31}{How learning rate changes over epochs}{figure.2.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Normalization}{32}{section.2.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.32}{\ignorespaces Normalization}}{32}{figure.2.32}\protected@file@percent }
\newlabel{fig:enter-label}{{2.32}{32}{Normalization}{figure.2.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.33}{\ignorespaces Batch Normalization}}{33}{figure.2.33}\protected@file@percent }
\newlabel{fig:enter-label}{{2.33}{33}{Batch Normalization}{figure.2.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.34}{\ignorespaces Inference Time}}{33}{figure.2.34}\protected@file@percent }
\newlabel{fig:enter-label}{{2.34}{33}{Inference Time}{figure.2.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.35}{\ignorespaces Layer Normalization}}{34}{figure.2.35}\protected@file@percent }
\newlabel{fig:enter-label}{{2.35}{34}{Layer Normalization}{figure.2.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Regularization}{34}{section.2.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.36}{\ignorespaces Dropout}}{35}{figure.2.36}\protected@file@percent }
\newlabel{fig:enter-label}{{2.36}{35}{Dropout}{figure.2.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.37}{\ignorespaces Weight Decay}}{35}{figure.2.37}\protected@file@percent }
\newlabel{fig:enter-label}{{2.37}{35}{Weight Decay}{figure.2.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.38}{\ignorespaces Early Stopping with Patience}}{36}{figure.2.38}\protected@file@percent }
\newlabel{fig:enter-label}{{2.38}{36}{Early Stopping with Patience}{figure.2.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.12}Evaluation and Debugging}{36}{section.2.12}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.39}{\ignorespaces Confusion Matrix}}{37}{figure.2.39}\protected@file@percent }
\newlabel{fig:enter-label}{{2.39}{37}{Confusion Matrix}{figure.2.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.40}{\ignorespaces F1 Score}}{37}{figure.2.40}\protected@file@percent }
\newlabel{fig:enter-label}{{2.40}{37}{F1 Score}{figure.2.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.41}{\ignorespaces Confusion Matrix Example}}{37}{figure.2.41}\protected@file@percent }
\newlabel{fig:enter-label}{{2.41}{37}{Confusion Matrix Example}{figure.2.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.42}{\ignorespaces t-SNE for 2D projection and visualization of data structure}}{38}{figure.2.42}\protected@file@percent }
\newlabel{fig:enter-label}{{2.42}{38}{t-SNE for 2D projection and visualization of data structure}{figure.2.42}{}}
\@setckpt{chapters/ann}{
\setcounter{page}{39}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{2}
\setcounter{enumiii}{3}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{12}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{42}
\setcounter{table}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{82}
\setcounter{tcbrastercolumn}{1}
\setcounter{tcbrasterrow}{1}
\setcounter{tcbrasternum}{1}
\setcounter{tcbraster}{0}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{tcblisting}{0}
\setcounter{section@level}{0}
\setcounter{Item}{51}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{17}
\setcounter{lstlisting}{0}
}

\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Graph Neural Networks (GNNs)}{126}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Motivation}{126}{section.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Why GNNs?}}{126}{figure.8.1}\protected@file@percent }
\newlabel{fig:enter-label}{{8.1}{126}{Why GNNs?}{figure.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Examples of Graphs}}{127}{figure.8.2}\protected@file@percent }
\newlabel{fig:enter-label}{{8.2}{127}{Examples of Graphs}{figure.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Deep Sets}{127}{section.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces Omitting positional encoding from transformers}}{127}{figure.8.3}\protected@file@percent }
\newlabel{fig:enter-label}{{8.3}{127}{Omitting positional encoding from transformers}{figure.8.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Model must be invariant to the order of the items}}{128}{figure.8.4}\protected@file@percent }
\newlabel{fig:enter-label}{{8.4}{128}{Model must be invariant to the order of the items}{figure.8.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces Deep Sets}}{128}{figure.8.5}\protected@file@percent }
\newlabel{fig:enter-label}{{8.5}{128}{Deep Sets}{figure.8.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Graphs}{129}{section.8.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Learning edge weights (attention scores) in a fully-connected graph}}{129}{figure.8.6}\protected@file@percent }
\newlabel{fig:enter-label}{{8.6}{129}{Learning edge weights (attention scores) in a fully-connected graph}{figure.8.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces Adjacency matrix (1 = connection; 0 = no connection)}}{129}{figure.8.7}\protected@file@percent }
\newlabel{fig:enter-label}{{8.7}{129}{Adjacency matrix (1 = connection; 0 = no connection)}{figure.8.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces Graph}}{130}{figure.8.8}\protected@file@percent }
\newlabel{fig:enter-label}{{8.8}{130}{Graph}{figure.8.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces Indices and naming are arbitrary}}{130}{figure.8.9}\protected@file@percent }
\newlabel{fig:enter-label}{{8.9}{130}{Indices and naming are arbitrary}{figure.8.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.10}{\ignorespaces Invariance and Equivariance}}{130}{figure.8.10}\protected@file@percent }
\newlabel{fig:enter-label}{{8.10}{130}{Invariance and Equivariance}{figure.8.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Graph Neural Networks}{131}{section.8.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.11}{\ignorespaces Message passing and application examples}}{131}{figure.8.11}\protected@file@percent }
\newlabel{fig:enter-label}{{8.11}{131}{Message passing and application examples}{figure.8.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.12}{\ignorespaces Message Passing}}{131}{figure.8.12}\protected@file@percent }
\newlabel{fig:enter-label}{{8.12}{131}{Message Passing}{figure.8.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces Read-out function}}{132}{figure.8.13}\protected@file@percent }
\newlabel{fig:enter-label}{{8.13}{132}{Read-out function}{figure.8.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.14}{\ignorespaces 1.\textbf  { Convolutional}: Multiply importance of each neighbour by scalar and summing; \newline  2. \textbf  {Attentional}: Use attention mechanism to do weighted summation; \newline  3. \textbf  {Message-Passing}: Pass all embeddings between target node and neighbouring nodes computed by neural network, then aggregate}}{132}{figure.8.14}\protected@file@percent }
\newlabel{fig:enter-label}{{8.14}{132}{1.\textbf { Convolutional}: Multiply importance of each neighbour by scalar and summing; \newline 2. \textbf {Attentional}: Use attention mechanism to do weighted summation; \newline 3. \textbf {Message-Passing}: Pass all embeddings between target node and neighbouring nodes computed by neural network, then aggregate}{figure.8.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Graph Convolutional Networks (GCNs)}{133}{section.8.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.15}{\ignorespaces Stacking GCNs}}{133}{figure.8.15}\protected@file@percent }
\newlabel{fig:enter-label}{{8.15}{133}{Stacking GCNs}{figure.8.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}Graph Attention Networks (GAT)}{134}{section.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.7}PyTorch Implementation}{134}{section.8.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.16}{\ignorespaces Toxicity classifier}}{134}{figure.8.16}\protected@file@percent }
\newlabel{fig:enter-label}{{8.16}{134}{Toxicity classifier}{figure.8.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.17}{\ignorespaces Dense Implementation}}{135}{figure.8.17}\protected@file@percent }
\newlabel{fig:enter-label}{{8.17}{135}{Dense Implementation}{figure.8.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.18}{\ignorespaces Sparse implementation with PYG}}{135}{figure.8.18}\protected@file@percent }
\newlabel{fig:enter-label}{{8.18}{135}{Sparse implementation with PYG}{figure.8.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.19}{\ignorespaces Sparse Implementation}}{136}{figure.8.19}\protected@file@percent }
\newlabel{fig:enter-label}{{8.19}{136}{Sparse Implementation}{figure.8.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.20}{\ignorespaces Batching in dense implementation}}{136}{figure.8.20}\protected@file@percent }
\newlabel{fig:enter-label}{{8.20}{136}{Batching in dense implementation}{figure.8.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.21}{\ignorespaces Batching in sparse implementation}}{137}{figure.8.21}\protected@file@percent }
\newlabel{fig:enter-label}{{8.21}{137}{Batching in sparse implementation}{figure.8.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.22}{\ignorespaces Dataloader \& Dataset}}{137}{figure.8.22}\protected@file@percent }
\newlabel{fig:enter-label}{{8.22}{137}{Dataloader \& Dataset}{figure.8.22}{}}
\@setckpt{chapters/gnn}{
\setcounter{page}{138}
\setcounter{equation}{0}
\setcounter{enumi}{3}
\setcounter{enumii}{1}
\setcounter{enumiii}{3}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{8}
\setcounter{section}{7}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{22}
\setcounter{table}{0}
\setcounter{tcbbreakpart}{1}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{182}
\setcounter{tcbrastercolumn}{1}
\setcounter{tcbrasterrow}{1}
\setcounter{tcbrasternum}{1}
\setcounter{tcbraster}{0}
\setcounter{parentequation}{0}
\setcounter{lstnumber}{1}
\setcounter{tcblisting}{0}
\setcounter{section@level}{0}
\setcounter{Item}{113}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{68}
\setcounter{lstlisting}{0}
}
